{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the necessay libraries \n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import regex as re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#The three libraries here will not be used but are imported to demonstrate the different methods of analysis that can be used\n",
    "\n",
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import osmnx as ox\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading in the CSV\n",
    "\n",
    "cal = pd.read_csv('Calgary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function for ease of use\n",
    "def clean_text(text):\n",
    "    # Removing numbers and punctuation\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    # Converting words to lowercase and splitting them\n",
    "    words = text.lower().split()\n",
    "    \n",
    "    # Removing short words\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    \n",
    "    # Lemmatizing words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    \n",
    "    # Appeding the text in a manner that allows it to be added as a dataframe column\n",
    "    clean_text = ' '.join(words)\n",
    "    return clean_text\n",
    "\n",
    "# Apply the cleaning function to the 'text' column\n",
    "cal['clean_text'] = cal['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sia = SentimentIntensityAnalyzer()\n",
    "#cal['polarity_score'] = cal['clean_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "#cal['polarity'] = cal['polarity_score'].apply(lambda x: 'positive' if x >= 0 else 'negative')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending a column called polarity\n",
    "cal['polarity'] = cal['stars_y'].apply(lambda x: 'positive' if x >= 4 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(cal['clean_text'], cal['polarity'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenising the text and extracting features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train = vectorizer.fit_transform(X_train).toarray()\n",
    "X_test = vectorizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "\n",
    "#a)\n",
    "#svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "#svm.fit(X_train, y_train)\n",
    "\n",
    "#b)\n",
    "# Predict the polarity of the venue for the testing set\n",
    "#y_pred = svm.predict(X_test)\n",
    "\n",
    "#c)\n",
    "# Evaluate the performance of the model using accuracy score\n",
    "#accuracy = accuracy_score(y_test, y_pred)\n",
    "#print('Accuracy:', accuracy)\n",
    "\n",
    "#d)\n",
    "# Calculate precision, recall, and F1-score\n",
    "#report = classification_report(y_test, y_pred)\n",
    "#print(report)\n",
    "\n",
    "#e)\n",
    "# Calculate the confusion matrix\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Create the confusion matrix display\n",
    "#cmd = ConfusionMatrixDisplay(cm, display_labels=svm.classes_)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "#cmd.plot()\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multinomial Naive Bayes Classifier\n",
    "\n",
    "#a)\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#b)\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "#c)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "#d)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "#e)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=nb.classes_)\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "#a)\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#b)\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "#c)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "#d)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "#e)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=dt.classes_)\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Classifier\n",
    "\n",
    "#a)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#b)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "#c)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "#d)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "#e)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=rf.classes_)\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression Model\n",
    "\n",
    "#a)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#b)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "#c)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "#d)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n",
    "\n",
    "#e)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=lr.classes_)\n",
    "cmd.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the coordinates for Calgary\n",
    "ox.geocode(\"Calgary, Canada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a folium map with the coordinates\n",
    "calgary_coords = [51.0460954, -114.065465]\n",
    "map = folium.Map(location=calgary_coords, zoom_start=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 2 new columns called postive and negative from the polarity column\n",
    "cal[['positive', 'negative']] = cal['polarity'].apply(lambda x: (True, False) if x == 'positive' else (False, True)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the cal dataframe into a gdf\n",
    "gdf = gpd.GeoDataFrame(cal, geometry=gpd.points_from_xy(cal.longitude, cal.latitude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the MarkerCluster plugin\n",
    "useful_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "# Creating a loop that generates clusters and adds them to the map\n",
    "\n",
    "# The value has been chosen as 2 as the average was 1.2\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['useful'] > 2:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='blue')).add_to(useful_cluster)\n",
    "\n",
    "#the same steps have been repeated for the other two tags\n",
    "\n",
    "funny_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "# The value has been chosen as 1 as the average was 0.39\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['funny'] > 1:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='orange')).add_to(funny_cluster)\n",
    "\n",
    "cool_cluster = MarkerCluster().add_to(map)\n",
    "\n",
    "# The value has been chosen as 1 as the average was 0.39\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['cool'] > 1:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='purple')).add_to(cool_cluster)\n",
    "\n",
    "map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 maps folllowing this are the tag maps isolated from each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usefulmap = folium.Map(location=calgary_coords, zoom_start=13)\n",
    "\n",
    "useful_cluster = MarkerCluster().add_to(usefulmap)\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['useful'] > 2:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='blue')).add_to(useful_cluster)\n",
    "\n",
    "usefulmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funnymap = folium.Map(location=calgary_coords, zoom_start=13)\n",
    "\n",
    "funny_cluster = MarkerCluster().add_to(funnymap)\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['funny'] > 1:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='orange')).add_to(funny_cluster)\n",
    "\n",
    "funnymap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coolmap = folium.Map(location=calgary_coords, zoom_start=13)\n",
    "\n",
    "cool_cluster = MarkerCluster().add_to(coolmap)\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['cool'] > 1:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='purple')).add_to(cool_cluster)\n",
    "\n",
    "coolmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posimap = folium.Map(location=calgary_coords, zoom_start=13)\n",
    "\n",
    "posi_cluster = MarkerCluster().add_to(posimap)\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['positive'] > 0:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='green')).add_to(posi_cluster)\n",
    "\n",
    "posimap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negmap = folium.Map(location=calgary_coords, zoom_start=13)\n",
    "\n",
    "neg_cluster = MarkerCluster().add_to(negmap)\n",
    "\n",
    "for _, row in gdf.iterrows():\n",
    "    if row['negative'] > 0:\n",
    "        folium.Marker(location=[row['latitude'], row['longitude']], \n",
    "                      icon=folium.Icon(color='red')).add_to(neg_cluster)\n",
    "\n",
    "negmap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total count of the data across both the polarity maps is 82182, which is the total number of rows in the dataset, validating that each review has been assigned a polarity score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
